Hi, my name is LH. My background is in biochemistry, and before Hb I worked first in academic research labs and then at a biotech startup in SSF. There I got to work closely with engineers and developers and got to see the process of programming intimately, and after a while, I was like "hey, what they're doing seems like a lot more fun than what I'm doing."
My project is called Novel Idea. It uses book information scraped from Goodreads to recommend books to users based on information they input, and uses machine learning to classify reviews into positive and negative categories. I used a Flask framework that talked to a postgres db via SQLAlchemy, and I have 45% test coverage.
So first I will show you the scraped data and talk about how I obtained it. To get this nice book information, I used the Python module Scrapy to write spiders. I have 473 books and over 10,000 reviews in my database. Most of these come from a list on Goodreads called "Books that deserve a higher rating". Later we'll see why I chose that list. My first spider, called Books, follows each book link from the main list page and scrapes title, author, summary, and picture url from each book's page. My second spider, called Reviews, starts with the main list page, follows each book link, then follows each review link to an individual review page to scrape the text and the title of the book. When loading the db, I could then match each review to its book object using the title. There are a couple reasons for this convolution, the most important one being that in order to create a dictionary that included book information and review text, I would have to pass data across response objects in the spider, which is not straightforward. In my next sprint, I plan to refactor these spiders to scrape in a recursive fashion.
There is a search feature where you can search for a specific book by title that will autocomplete with books from the db, and you can go directly to the book's page. This page has the scraped information about the book, as well as an option to give it between 1 and 5 stars. You can also see the top genres that Goodreads users have given the book. This information is factored into the recommendation algorithm
On the user's profile page, you can see the books you have rated, as well as any genres you have favorited. These buttons update the db via ajax calls, so you can favorite or delete genres without leaving or refreshing the page. The call to add a new genre also checks whether that genre already exists for that user, and will not let you add the same genre twice.
You can page through the genres that exist in the database via the More and Back buttons, which use ajax calls that pass a javascript counter to a sqlalchemy call that offsets the database query accordingly.
To explain the rec algorithm, I will first explain my db model. In my database, my User table has a many to many relationship with the Genre table, mediated by an association table called UserGenre so that users can have favorite genres. Similarly, Users and Books have a many to many relationship which is mediated by the Ratings table, which stores how many stars a user gives a book, as well as the text of a written review. Thirdly, Books and Genres have a many to many relationship that is mediated by another association table called BookGenres.
So the rec algorithm takes the list of a user's favorite genres and queries the db to see if there is any book that has a list of genres that perfectly matches that of the user. If you have favorited very disparate genres, such a book may not exist, so the algorithm will also recommend books that have two or more genres in common with the user.
The app provides visualization of genre information so that a user can better calibrate their choices of genre in order to get better recommendations. Or, if like me, you are just curious about the dataset. This chart was made in Chart.js
Probably the most exciting feature of this app is the machine learning analysis of the scraped reviews from Goodreads. I built a sentiment analyzer in Python using sci kit learn and numpy. I used the Naive Bayes algorithm to classify reviews into binary categories of positive and negative. I treated 1 and 2 star reviews as negative reviews and 4 and 5 star reviews as positive reviews, throwing out 3 star reviews. I chose to binaririze the data in this way because it generally produces a higher precision and recall than algorithms that try to categorize in multiple categories. I trained my classifier by feeding it the text of the reviews, using the number of stars as already-assigned labels. In brief, the Naive Bayes algorithm works by calculating the probability of a given word appearing in a positive or negative review based on the frequency that it actually does. The probabilities of each word are calculated independently, which is why it is called "naive". Even though this algorithm sounds ridiculously simple, it can produce pretty good results. When I used a set of books that had a roughly equal number of negative and positive reviews, I received a precision of about 85% and a recall of about 80%. In other words, 85% of the predicted negative reviews were actually negative reviews, and about 80% of the actual negative reviews were predicted to be negative reviews. The fun part of this comes when I looked at the words that the classifier considered to be most likely to respectively appear in negative and positive reviews. Some of them make sense - people on Goodreads use the abbrev "DNF" for did not finish, and overuse and congratulatory you might expect. The funny part is that the classifier also brought up words like "coworkers" and "sylvia". As it turns out, there is a certain book called Nickeled and Dimed that got a lot of negative reviews, and one of the things readers complained the most about was the protagonist's harsh treatment of her coworkers. Similarly, "faire" came from a lot of poor reviews of Ayn Rand's books that mentioned laisse-faire capitalism. Because these words appeared most prominently in negative reviews and these feature words are spread out among reviews of a lot of different books, uncommon words from specific books really stood out.
It goes to show that as any data scientist knows, your algorithm is only as good as the quality of your data.
In conclusion, I have several features planned out for my next sprint on this project. I want to make a feature where you can type in a review of a book and the classifier will guess how many stars you are giving the book. This will require some refactoring of my classifier to perform classification on a single review based on the data I've already fed it. I also want to create boards where a user can save their recommendations. Thirdly, I want to add more complex visualization of how genres overlap with each other because I want to see whether it falls across the lines you'd expect. Thank you for your attention and goodnight.
